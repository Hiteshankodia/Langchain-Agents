{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain-openai tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(\n",
    "   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub \n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Tools \n",
    "\n",
    "tools = [TavilySearchResults(max_results=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Demo Projects\\Agents\\Langchain-Agents\\venv\\Lib\\site-packages\\langsmith\\client.py:277: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create Agent \n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLangChain is an open-source framework designed to simplify the development of applications that leverage large language models (LLMs) like OpenAI's GPT or other similar models. It provides tools, abstractions, and integrations to make it easier for developers to build complex applications that involve natural language processing, reasoning, and decision-making.\n",
      "\n",
      "LangChain is particularly useful for building applications that require chaining together multiple tasks or components, such as retrieval-augmented generation (RAG), conversational agents, summarization, and more. It enables developers to seamlessly integrate LLMs with external data sources, APIs, and other tools, allowing for more dynamic and interactive applications.\n",
      "\n",
      "### Key Features of LangChain:\n",
      "1. **Chains**: LangChain allows developers to create sequences of calls to LLMs and other utilities, enabling multi-step workflows.\n",
      "2. **Agents**: It supports the creation of agents that can interact with external tools, APIs, or databases to retrieve or process information dynamically.\n",
      "3. **Memory**: LangChain includes memory capabilities, enabling applications to maintain context over time, such as in conversations or multi-turn interactions.\n",
      "4. **Integrations**: It provides integrations with various tools, APIs, and data sources, such as vector databases, search engines, and document loaders.\n",
      "5. **Prompt Templates**: LangChain makes it easy to design and manage prompts for LLMs, ensuring consistency and reusability.\n",
      "6. **Evaluation**: Tools for testing and evaluating LLM-based applications are included to improve performance and reliability.\n",
      "\n",
      "LangChain is widely used for building chatbots, question-answering systems, knowledge retrieval applications, and other AI-powered tools that require complex workflows or reasoning. Developers appreciate its modularity and flexibility, making it a popular choice for working with LLMs.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is langChain?',\n",
       " 'output': \"LangChain is an open-source framework designed to simplify the development of applications that leverage large language models (LLMs) like OpenAI's GPT or other similar models. It provides tools, abstractions, and integrations to make it easier for developers to build complex applications that involve natural language processing, reasoning, and decision-making.\\n\\nLangChain is particularly useful for building applications that require chaining together multiple tasks or components, such as retrieval-augmented generation (RAG), conversational agents, summarization, and more. It enables developers to seamlessly integrate LLMs with external data sources, APIs, and other tools, allowing for more dynamic and interactive applications.\\n\\n### Key Features of LangChain:\\n1. **Chains**: LangChain allows developers to create sequences of calls to LLMs and other utilities, enabling multi-step workflows.\\n2. **Agents**: It supports the creation of agents that can interact with external tools, APIs, or databases to retrieve or process information dynamically.\\n3. **Memory**: LangChain includes memory capabilities, enabling applications to maintain context over time, such as in conversations or multi-turn interactions.\\n4. **Integrations**: It provides integrations with various tools, APIs, and data sources, such as vector databases, search engines, and document loaders.\\n5. **Prompt Templates**: LangChain makes it easy to design and manage prompts for LLMs, ensuring consistency and reusability.\\n6. **Evaluation**: Tools for testing and evaluating LLM-based applications are included to improve performance and reliability.\\n\\nLangChain is widely used for building chatbots, question-answering systems, knowledge retrieval applications, and other AI-powered tools that require complex workflows or reasoning. Developers appreciate its modularity and flexibility, making it a popular choice for working with LLMs.\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run agent\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\":\"What is langChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input'] optional_variables=['chat_history'] input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001F869B2C180>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001F869B2C180>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]} partial_variables={'chat_history': []} metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-tools-agent', 'lc_hub_commit_hash': 'c18672812789a3b9697656dd539edf0120285dcae36396d0b548ae42a4ed66f5'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
